{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"kernelVersion","sourceId":160817392}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-01-29T03:32:49.793935Z\",\"iopub.execute_input\":\"2024-01-29T03:32:49.794714Z\",\"iopub.status.idle\":\"2024-01-29T03:32:49.802333Z\",\"shell.execute_reply.started\":\"2024-01-29T03:32:49.794676Z\",\"shell.execute_reply\":\"2024-01-29T03:32:49.801313Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-01-29T03:32:49.805605Z\",\"iopub.execute_input\":\"2024-01-29T03:32:49.805965Z\",\"iopub.status.idle\":\"2024-01-29T03:34:54.204960Z\",\"shell.execute_reply.started\":\"2024-01-29T03:32:49.805932Z\",\"shell.execute_reply\":\"2024-01-29T03:34:54.203837Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nimport torch\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import SubsetRandomSampler\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets\nimport matplotlib.pyplot as plt\nfrom model2 import CNN \ntorch.manual_seed(4)\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nlossfunc = nn.CrossEntropyLoss() \n\ntrain_data = datasets.MNIST(\n    root = 'data',\n    train = True,                         \n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,))\n    ]) ,       \n    download = True,            \n)\ntest_data = datasets.MNIST(\n    root = 'data', \n    train = False, \n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,))\n    ]) \n)\n\ntrain_size=int(0.8 * len(train_data))\nval_size = len(train_data) - train_size\n\n\ntrain_sampler = SubsetRandomSampler(range(train_size))\nval_sampler = SubsetRandomSampler(range(train_size, len(train_data)))\n\n\nloaders = {\n    'train' : torch.utils.data.DataLoader(train_data, \n                                          batch_size=100,\n                                          sampler=train_sampler,\n                                          #shuffle=True, \n                                          num_workers=1),\n    'val' : torch.utils.data.DataLoader(train_data, \n                                          batch_size=100,\n                                          sampler=val_sampler,\n                                          #shuffle=True, \n                                          num_workers=1),\n    \n    'test'  : torch.utils.data.DataLoader(test_data, \n                                          batch_size=100, \n                                          shuffle=True, \n                                          num_workers=1),\n}\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = CNN().to(device)\noptimizer = optim.Adam(model.parameters(),lr=0.001,betas=(0.9,0.999))\n\n\nnum_epochs = 10\n\nlosslist = []\nbest_vacc=0.0\n\n#def train(num_epochs, cnn, loaders):\nmodel.train()\n    \n    # Train the model\ntotal_step = len(loaders['train'])\n    \n    \n    \nfor epoch in range(num_epochs):\n    correct=0\n    samples=0\n    totalLoss=0\n    for images,labels in loaders['train']:\n            \n            # gives batch data, normalize x when iterate train_loader\n        images = images.to(device)  # Assuming device is defined as torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n        labels = labels.to(device)\n        output = model(images)\n        loss = lossfunc(output, labels)\n            \n            # clear gradients for this training step\n        optimizer.zero_grad()\n            \n            # backpropagation, compute gradients\n        loss.backward()\n            \n            # apply gradients\n        optimizer.step()\n            \n        totalLoss += loss.item()\n            \n        _, predicted = torch.max(output, 1)\n        samples += labels.size(0)\n        correct += (predicted == labels).sum().item()\n            \n        \n    losslist.append(totalLoss/len(loaders['train']))\n    tacc = correct/samples\n    \n   \n\n\n\n    correct = 0\n    samples = 0    \n    model.eval()\n    with torch.no_grad():\n        for images, labels in loaders['val']:\n            images, labels = images.to(device), labels.to(device)\n            output = model(images)\n            \n            _, predicted = torch.max(output, 1)\n            samples += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    vacc = correct/samples\n    print(f\"Epoch {epoch+1}, Training Acc: {tacc:.3f}, Valset Acc: {vacc:.3f}\")\n    if vacc > best_vacc:\n        best_vacc = vacc\n        torch.save(model.state_dict(), 'weights.pth')\n        print('Weights Saved')\n   \n\n\n         \nplt.plot(range(1, num_epochs + 1), losslist, label='Training Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss over Epochs')\nplt.legend()\nplt.show()\n\n# %% [code]\n","metadata":{"_uuid":"ca8a4e64-e53a-4021-a124-8c1d56e82b78","_cell_guid":"7f01a658-ea00-4cd5-b23b-8d7866cb4e22","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}